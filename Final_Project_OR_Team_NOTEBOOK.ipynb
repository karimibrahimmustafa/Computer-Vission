{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Project_OR_Team_NOTEBOOK.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN98FkMRFfVU",
        "colab_type": "text"
      },
      "source": [
        "**Imported Libraries:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXS_vwD6Dqvq",
        "colab_type": "code",
        "outputId": "f2960849-b156-4cc2-f192-bffcfaca9a38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import the needed libraries\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import GlobalAveragePooling2D, InputLayer, Dense, Reshape, Conv2D, MaxPooling2D, Input, TimeDistributed, GlobalMaxPooling1D, BatchNormalization, ZeroPadding2D, Dropout, Activation, Flatten, LSTM\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.utils import Sequence\n",
        "from keras import optimizers\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import glob\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J8diEVPPkgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7mlbV0qPoWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip the dataset\n",
        "!unzip -q 'drive/My Drive/MRNet-v1.0.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGgZXAUbFpPS",
        "colab_type": "text"
      },
      "source": [
        "**Helper Functions and Classes:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlI2b-ejlkma",
        "colab_type": "text"
      },
      "source": [
        "Data generator class prepares the dataset for training or testing by doing the following:\n",
        "\n",
        "1.   Load the training, validation or testing data of the given plane.\n",
        "2.   Add 3 color channels to each case.\n",
        "3.   Load the labels of the corresponding diagnosis. \n",
        "4.   Return a batch of size 1.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_XKpIzAPwBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data generator class\n",
        "# task = 0 - training, task = 1 - validation, task =  2 testing\n",
        "class data_generator(Sequence):\n",
        "  def __init__(self, directory, diagnosis, plane, task=0):\n",
        "    self.directory = directory\n",
        "    self.diagnosis = diagnosis\n",
        "    self.plane = plane\n",
        "    self.task = task\n",
        "    self.labels = self.load_labels_from_dir()\n",
        "    if self.task == 0 or self.task == 1:\n",
        "      self.target_path = self.directory + 'train/{}/'.format(plane)\n",
        "      self.target_labels = self.labels['train-{}'.format(diagnosis)]      \n",
        "    elif self.task == 2:\n",
        "      self.target_path = self.directory + 'valid/{}/'.format(plane)\n",
        "      self.target_labels = self.labels['valid-{}'.format(diagnosis)]\n",
        "    self.ids = list(self.target_labels['exam'])\n",
        "    self.Y = list(self.target_labels['label'])\n",
        "    if self.task == 0:\n",
        "      self.ids = self.ids[:1017]\n",
        "      self.Y = self.Y[:1017]\n",
        "    elif self.task == 1:\n",
        "      self.ids = self.ids[1017:]\n",
        "      self.Y = self.Y[1017:]\n",
        "    self.ids = map(lambda id: '0' * (4 - len(str(id))) + str(id), self.ids)\n",
        "    self.paths = [self.target_path + id + '.npy' for id in self.ids]\n",
        "  def __len__(self):\n",
        "    return len(self.Y)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    batch_y = np.expand_dims(np.array(self.Y[idx]), 0)\n",
        "    batch_x = np.load(self.paths[idx])\n",
        "    batch_x = self.add_color_channels(batch_x)\n",
        "    batch_x = np.expand_dims(batch_x, 0)\n",
        "    return batch_x, batch_y\n",
        "\n",
        "  def load_labels_from_dir(self):\n",
        "    labels = {}\n",
        "    for file in glob.glob(os.path.join(self.directory, '*.csv')):\n",
        "      file_name = os.path.basename(file)\n",
        "      labels[os.path.splitext(file_name)[0]] = pd.read_csv(file, index_col=False, names=['exam', 'label'])\n",
        "    return labels\n",
        "  \n",
        "  def add_color_channels(self, im):\n",
        "    return np.repeat(im[:, :, :, np.newaxis], 3, axis=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYRK02c3kUrn",
        "colab_type": "text"
      },
      "source": [
        "A function used to prepare the input data for the Logistic Regression layer.\n",
        "This input is the result of the 3 planes' models predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnTkUmSoUPTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input: models of 3 planes for a signle diagnosis, data generators of the 3 planes\n",
        "# output: array containing the predictions of the 3 models\n",
        "def predict_single_diagnosis(axial_model, sagittal_model, coronal_model, axial_data, sagittal_data, coronal_data):\n",
        "  all_predictions = []\n",
        "  for i in range (len(axial_data)):\n",
        "    prediction_row = []\n",
        "    x1, y1 = axial_data[i]\n",
        "    prediction_row.append(axial_model.predict(x1)[0][0])\n",
        "    x2, y2 = sagittal_data[i]\n",
        "    prediction_row.append(sagittal_model.predict(x2)[0][0])\n",
        "    x3, y3 = coronal_data[i]\n",
        "    prediction_row.append(coronal_model.predict(x3)[0][0])\n",
        "    all_predictions.append(prediction_row)\n",
        "  \n",
        "  return all_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lpt3FN5YFzXF",
        "colab_type": "text"
      },
      "source": [
        "**Implemented Networks:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri1Hxj8UkEcF",
        "colab_type": "text"
      },
      "source": [
        "1. AlexNet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsVvcNUiF3_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#AlexNet\n",
        "def alexnet_from_scratch(input_layer):\n",
        "  squeeze_layer = keras.layers.Lambda(lambda x: tf.keras.backend.squeeze(x, 0))(input_layer)\n",
        "  normalization = BatchNormalization()(squeeze_layer)\n",
        "  \n",
        "  x = Conv2D(96, (11, 11), strides = (4, 4), activation = 'relu')(normalization)\n",
        "  x = MaxPooling2D((3,3), strides=(2,2))(x)\n",
        "  x = Conv2D(256, (5, 5), strides = (1, 1), padding = 'same', activation = 'relu')(x)\n",
        "  x = MaxPooling2D((3,3), strides=(2,2))(x)\n",
        "  x = Conv2D(384, (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(x)\n",
        "  x = Conv2D(384, (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(x)\n",
        "  x = Conv2D(256, (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(x)\n",
        "  x = MaxPooling2D((3,3), strides=(2,2))(x)\n",
        "\n",
        "  global_average_pool = GlobalAveragePooling2D()(x)\n",
        "  global_average_pool = BatchNormalization()(global_average_pool)\n",
        "  max_layer = keras.layers.Lambda(lambda x: tf.math.reduce_max(\n",
        "      x, axis=0, keepdims=True, name=None\n",
        "  ))(global_average_pool)\n",
        "  max_layer = BatchNormalization()(max_layer)\n",
        "  dense_layer = keras.layers.Dense(1, activation = 'sigmoid')(max_layer)\n",
        "  dense_layer = Dropout(0.6)(dense_layer)\n",
        "\n",
        "  model = keras.Model(input_layer, dense_layer)\n",
        "  sgd = optimizers.SGD(lr=0.008, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "  model.compile(optimizer=sgd, loss='binary_crossentropy', metrics = ['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwbA3zk3kHW8",
        "colab_type": "text"
      },
      "source": [
        "2. VGG:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRFmJtovF46L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  # VGG model from scratch\n",
        "def vgg_from_scratch(input_layer):\n",
        "  squeeze_layer = keras.layers.Lambda(lambda x: tf.keras.backend.squeeze(\n",
        "      x, 0))(input_layer)\n",
        "  normalization = BatchNormalization()(squeeze_layer)\n",
        "  x = Conv2D(64, (3, 3), activation='relu')(normalization)\n",
        "  x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "  x = MaxPooling2D((2,2), strides=(2,2))(x)\n",
        "  x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "  x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "  x = MaxPooling2D((2,2), strides=(2,2))(x)\n",
        "  x = Conv2D(256, (3, 3), activation='relu')(x)\n",
        "  x = Conv2D(256, (3, 3), activation='relu')(x)\n",
        "  x = Conv2D(256, (3, 3), activation='relu')(x)\n",
        "  x = MaxPooling2D((2,2), strides=(2,2))(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu')(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu')(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu')(x)\n",
        "  x = MaxPooling2D((2,2), strides=(2,2))(x)\n",
        "\n",
        "  x = Conv2D(512, (3, 3), activation='relu')(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu')(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu')(x)\n",
        "  x = MaxPooling2D((2,2), strides=(2,2))(x)\n",
        "\n",
        "  global_average_pool = GlobalAveragePooling2D()(x)\n",
        "  global_average_pool = BatchNormalization()(global_average_pool)\n",
        "  max_layer = keras.layers.Lambda(lambda x: tf.math.reduce_max(\n",
        "      x, axis=0, keepdims=True, name=None\n",
        "  ))(global_average_pool)\n",
        "  dense_layer = keras.layers.Dense(1, activation = 'sigmoid')(max_layer)\n",
        "  dense_layer = Dropout(0.25)(dense_layer)\n",
        "  model = keras.Model(input_layer, dense_layer)\n",
        "  opt = optimizers.Adadelta(lr=0.001, decay=1e-6)\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics = ['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA9n0kIrkJyJ",
        "colab_type": "text"
      },
      "source": [
        "3. ResNet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn3AOeL0F4tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_from_scratch(input_layer):\n",
        "  squeeze_layer = keras.layers.Lambda(lambda x: tf.keras.backend.squeeze(\n",
        "      x, 0))(input_layer)\n",
        "  normalization = BatchNormalization()(squeeze_layer)\n",
        "  x = ZeroPadding2D((1,1))(normalization)\n",
        "  x = Conv2D(64, 7, strides=(2, 2), activation=\"relu\")(x)\n",
        "\n",
        "  inp = MaxPooling2D((3, 3),padding='same', strides=(2, 2))(x)\n",
        "  x = Conv2D(64, 3, padding='same', activation=\"relu\")(inp)\n",
        "  x = Conv2D(64, 3, padding='same', activation=\"linear\")(x)\n",
        "  inp = add([x, inp])\n",
        "  inp = Activation('relu')(inp)\n",
        "  x = Conv2D(64, 3, padding='same', activation=\"relu\")(inp)\n",
        "  x = Conv2D(64, 3, padding='same', activation=\"linear\")(x)\n",
        "  x = add([x, inp])\n",
        "  inp = Activation('relu')(x)\n",
        "\n",
        "  inp = MaxPooling2D((3, 3),padding='same', strides=(2, 2))(x)\n",
        "  x = Conv2D(128, 3, padding='same', activation=\"relu\")(inp)\n",
        "  x = Conv2D(128, 3, padding='same', activation=\"linear\")(x)\n",
        "  inp = Conv2D(128, 3, padding='same', activation=\"relu\")(inp)\n",
        "  inp = add([x, inp])\n",
        "  inp = Activation('relu')(inp)\n",
        "  x = Conv2D(128, 3, padding='same', activation=\"relu\")(inp)\n",
        "  x = Conv2D(128, 3, padding='same', activation=\"linear\")(x)\n",
        "  x = add([x, inp])\n",
        "  inp = Activation('relu')(x)\n",
        "\n",
        "  inp = MaxPooling2D((3, 3),padding='same', strides=(2, 2))(x)\n",
        "  x = Conv2D(256, 3, padding='same', activation=\"relu\")(inp)\n",
        "  x = Conv2D(256, 3, padding='same', activation=\"linear\")(x)\n",
        "  inp = Conv2D(256, 3, padding='same', activation=\"relu\")(inp)\n",
        "  inp = add([x, inp])\n",
        "  inp = Activation('relu')(inp)\n",
        "  x = Conv2D(256, 3, padding='same', activation=\"relu\")(inp)\n",
        "  x = Conv2D(256, 3, padding='same', activation=\"linear\")(x)\n",
        "  x = add([x, inp])\n",
        "  inp = Activation('relu')(x)\n",
        "\n",
        "  inp = MaxPooling2D((3, 3),padding='same', strides=(2, 2))(x)\n",
        "  x = Conv2D(512, 3, padding='same', activation=\"relu\")(inp)\n",
        "  x = Conv2D(512, 3, padding='same', activation=\"linear\")(x)\n",
        "  inp = Conv2D(512, 3, padding='same', activation=\"relu\")(inp)\n",
        "  inp = add([x, inp])\n",
        "  inp = Activation('relu')(inp)\n",
        "  x = Conv2D(512, 3, padding='same', activation=\"relu\")(inp)\n",
        "  x = Conv2D(512, 3, padding='same', activation=\"linear\")(x)\n",
        "  x = add([x, inp])\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  resnet = BatchNormalization()(x)\n",
        "\n",
        "  global_average_pool = GlobalAveragePooling2D()(resnet)\n",
        "  global_average_pool = BatchNormalization()(global_average_pool)\n",
        "  max_layer = keras.layers.Lambda(lambda x: tf.math.reduce_max(\n",
        "      x, axis=0, keepdims=True, name=None\n",
        "  ))(global_average_pool)\n",
        "  max_layer = BatchNormalization()(max_layer)\n",
        "  dense_layer = keras.layers.Dense(1, activation = 'sigmoid')(max_layer)\n",
        "  model = keras.Model(input_layer, dense_layer)\n",
        "  sgd = optimizers.SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "  model.compile(optimizer=sgd, loss='binary_crossentropy', metrics = ['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H2CsJXBgy4m",
        "colab_type": "text"
      },
      "source": [
        "4. Inception:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcOjCN5WF4im",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Conv(input_layer, f, k, p='same', s=(1,1)):\n",
        "  layer = layers.Conv2D(filters=f, kernel_size=k, strides=s, padding=p, kernel_regularizer=l2(0.0))(input_layer)\n",
        "  layer = layers.BatchNormalization(axis = 3)(layer)\n",
        "  layer = layers.Activation('relu')(layer)\n",
        "  return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FY8cwEtgv_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inception_from_scratch(inputLayer):\n",
        "    layer = Conv(inputLayer, 32, (3,3),s=(2,2), p='valid')\n",
        "    layer = Conv(layer, 32,(3,3) ,p = 'valid')\n",
        "    layer = Conv(layer, 64, (3,3))\n",
        "    layer = layers.MaxPooling2D((3,3), strides=(2,2))(layer)\n",
        "    layer = Conv(layer, 80, (1, 1), p='valid')\n",
        "    layer = Conv(layer, 192, (3, 3), p='valid')\n",
        "    layer = layers.MaxPooling2D((3, 3), strides=(2, 2))(layer)\n",
        "    \n",
        "    for x in range(3):\n",
        "        conv1 = Conv(layer, 64, (1, 1))\n",
        "    \n",
        "        conv3 = Conv(layer, 64, (1, 1))\n",
        "        conv3 = Conv(conv3, 96, (3, 3))\n",
        "        conv3 = Conv(conv3, 96, (3, 3))\n",
        "    \n",
        "        conv5 = Conv(layer, 48, (1, 1))\n",
        "        conv5 = Conv(conv5, 64, (5, 5))\n",
        "    \n",
        "        Pool = layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(layer)\n",
        "        Pool = Conv(Pool, 32, (1, 1))\n",
        "        layer = layers.concatenate([conv1, conv3, conv5, Pool],axis=3)\n",
        "    \n",
        "    \n",
        "    conv1 = Conv(layer, 384, (3, 3), s=(2, 2), p='valid')\n",
        "    \n",
        "    conv3 = Conv(layer, 64, (1, 1))\n",
        "    conv3 = Conv(conv3, 96, (3, 3))\n",
        "    conv3 = Conv(conv3, 96, (3, 3), s=(2, 2), p='valid')\n",
        "    \n",
        "    Pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(layer)\n",
        "    layer = layers.concatenate([conv1, conv3, Pool], axis=3)\n",
        "    \n",
        "    conv1 = Conv(layer, 192, (1, 1))\n",
        "    \n",
        "    conv7 = Conv(layer, 128, (1, 1))\n",
        "    conv7 = Conv(conv7, 128, (1, 7))\n",
        "    conv7 = Conv(conv7, 192, (7, 1))\n",
        "    \n",
        "    conv7_2 = Conv(layer, 128, (1, 1))\n",
        "    conv7_2 = Conv(conv7_2, 128, (7, 1))\n",
        "    conv7_2 = Conv(conv7_2, 128, (1, 7))\n",
        "    conv7_2 = Conv(conv7_2, 128, (7, 1))\n",
        "    conv7_2 = Conv(conv7_2, 192, (1, 7))\n",
        "    \n",
        "    Pool = layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(layer)\n",
        "    Pool = Conv(Pool, 192, (1, 1))\n",
        "    \n",
        "    \n",
        "    for x in range(2):\n",
        "      conv1 = Conv(layer, 192, (1, 1))\n",
        "    \n",
        "      conv7 = Conv(layer, 160, (1, 1))\n",
        "      conv7 = Conv(conv7, 160, (1, 7))\n",
        "      conv7 = Conv(conv7, 192, (7, 1))\n",
        "    \n",
        "      conv7_2 = Conv(layer, 160, (1, 1))\n",
        "      conv7_2 = Conv(conv7_2, 160, (7, 1))\n",
        "      conv7_2 = Conv(conv7_2, 160, (1, 7))\n",
        "      conv7_2 = Conv(conv7_2, 160, (7, 1))\n",
        "      conv7_2 = Conv(conv7_2, 192, (1, 7))\n",
        "    \n",
        "      Pool = layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(layer)\n",
        "      Pool = Conv(Pool, 192, (1, 1))\n",
        "    \n",
        "      layer = layers.concatenate([conv1, conv7, conv7_2, Pool],axis=3)\n",
        "    \n",
        "    conv1 = Conv(layer, 192, (1, 1))\n",
        "    \n",
        "    conv7 = Conv(layer, 192, (1, 1))\n",
        "    conv7 = Conv(conv7, 192, (1, 7))\n",
        "    conv7 = Conv(conv7, 192, (7, 1))\n",
        "    \n",
        "    conv7_2 = Conv(layer, 192, (1, 1))\n",
        "    conv7_2 = Conv(conv7_2, 192, (7, 1))\n",
        "    conv7_2 = Conv(conv7_2, 192, (1, 7))\n",
        "    conv7_2 = Conv(conv7_2, 192, (7, 1))\n",
        "    conv7_2 = Conv(conv7_2, 192, (1, 7))\n",
        "    \n",
        "    Pool = layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(layer)\n",
        "    Pool = Conv(Pool, 192, (1, 1))\n",
        "    \n",
        "    layer = layers.concatenate([conv1, conv7, conv7_2, Pool],axis=3)\n",
        "    \n",
        "    conv1 = Conv(layer, 192, (1, 1))\n",
        "    conv1 = Conv(layer, 320, (3,3),s=(2, 2),p='valid')\n",
        "    \n",
        "    conv7_2 = Conv(layer, 192, (1, 1))\n",
        "    conv7_2 = Conv(conv7_2, 192, (1, 7))\n",
        "    conv7_2 = Conv(conv7_2, 192, (7, 1))\n",
        "    conv7_2 = Conv(conv7_2, 192,(3,3),s=(2,2),p='valid')\n",
        "    \n",
        "    Pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(layer)\n",
        "    layer = layers.concatenate([conv1,conv7_2, Pool],axis=3)\n",
        "    \n",
        "    for i in range(2):\n",
        "        conv1 = Conv(layer, 320, (1, 1))\n",
        "    \n",
        "        conv3 = Conv(layer, 384, (1, 1))\n",
        "        conv3_11 = Conv(conv3, 384, (1, 3))\n",
        "        conv3_12 = Conv(conv3, 384, (3, 1))\n",
        "        conv3 = layers.concatenate([conv3_11,conv3_12],axis=3)\n",
        "    \n",
        "        conv32 = Conv(layer, 448, (1, 1))\n",
        "        conv32 = Conv(conv32, 384, (3, 3))\n",
        "        conv3_21 = Conv(conv32, 384, (1, 3))\n",
        "        conv3_22 = Conv(conv32, 384, (3, 1))\n",
        "        conv32 = layers.concatenate([conv3_21,conv3_22],axis=3)\n",
        "    \n",
        "        Pool = layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(layer)\n",
        "        Pool = Conv(Pool, 192, (1, 1))\n",
        "        layer = layers.concatenate([conv1,conv3,conv32, Pool],axis=3)\n",
        "    return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn1NheaQF5fo",
        "colab_type": "text"
      },
      "source": [
        "**Transfer Learning of VGG16**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6WU5O_0F_QN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transfer_learning_with_vgg(input_layer):\n",
        "  squeeze_layer = keras.layers.Lambda(lambda x: tf.keras.backend.squeeze(\n",
        "      x, 0))(input_layer)\n",
        "  normalization = BatchNormalization()(squeeze_layer)\n",
        "  vgg = VGG16(weights='imagenet',include_top=False)\n",
        "  for layer in vgg.layers:\n",
        "    layer.trainable = False\n",
        "  vgg = vgg(normalization)\n",
        "  global_average_pool = GlobalAveragePooling2D()(vgg)\n",
        "  global_average_pool = BatchNormalization()(global_average_pool)\n",
        "  max_layer = keras.layers.Lambda(lambda x: tf.math.reduce_max(\n",
        "      x, axis=0, keepdims=True, name=None\n",
        "  ))(global_average_pool)\n",
        "  dense_layer = keras.layers.Dense(1, activation = 'sigmoid')(max_layer)\n",
        "  dense_layer = Dropout(0.1)(dense_layer)\n",
        "  model = keras.Model(input_layer, dense_layer)\n",
        "  opt = optimizers.Adadelta(lr=0.01)\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics = ['accuracy'])\n",
        "  model.layers[3].trainable = False\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9qmkkViGAIW",
        "colab_type": "text"
      },
      "source": [
        "**Training Phase:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBNMAtJkTSoA",
        "colab_type": "text"
      },
      "source": [
        "Training steps for a single model (ex: meniscus, coronal) using a specific network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsBAiLTHiVEw",
        "colab_type": "code",
        "outputId": "420415b9-19b5-4f7f-dab4-383116786979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "input_layer = keras.Input(shape=(None,256,256,3))\n",
        "model = transfer_learning_with_vgg(input_layer)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, None, 256, 256, 3) 0         \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 256, 256, 3)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 256, 256, 3)       12        \n",
            "_________________________________________________________________\n",
            "vgg16 (Model)                multiple                  14714688  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "lambda_2 (Lambda)            (1, 512)                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, 1)                    513       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (1, 1)                    0         \n",
            "=================================================================\n",
            "Total params: 14,717,261\n",
            "Trainable params: 1,543\n",
            "Non-trainable params: 14,715,718\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01ZR-4YgGDYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = data_generator('MRNet-v1.0/', 'meniscus', 'coronal', task=0)\n",
        "valid_generator = data_generator('MRNet-v1.0/', 'meniscus', 'coronal', task=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd_kPAMVGEYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(train_generator, steps_per_epoch=1017, epochs=10, validation_data=valid_generator, validation_steps=113)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udIjX6K_T52-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,7)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKNDeQVPYOQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('drive/My Drive/vgg_coronal_meniscus.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3VcoQqj0uii",
        "colab_type": "text"
      },
      "source": [
        "# This notebook is a collective summary for the training that each one has done on his own notebooks to parallelize the training phase among us. So, in this part we only load the models that we trained previously"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YfI5lREGFJ3",
        "colab_type": "text"
      },
      "source": [
        "**Logistic Regression Layer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhrnwV2Y6SfR",
        "colab_type": "text"
      },
      "source": [
        "1. Loading the models of 3 planes:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiYNgrKCGS7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "axial_model = keras.models.load_model('drive/My Drive/vgg_axial_meniscus_tl.h5', custom_objects={'tf': tf})\n",
        "sagittal_model = keras.models.load_model('drive/My Drive/vgg_sagittal_meniscus_tl.h5', custom_objects={'tf': tf})\n",
        "coronal_model = keras.models.load_model('drive/My Drive/vgg_coronal_meniscus_tl.h5', custom_objects={'tf': tf})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNrGEZXHVps9",
        "colab_type": "text"
      },
      "source": [
        "2. Loading training data generator:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_ZsFUwLGT_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_axial_data_generator = data_generator('MRNet-v1.0/', 'meniscus', 'axial', task = 0)\n",
        "t_sagittal_data_generator = data_generator('MRNet-v1.0/', 'meniscus', 'sagittal', task = 0)\n",
        "t_coronal_data_generator = data_generator('MRNet-v1.0/', 'meniscus', 'coronal', task = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t57X6yfV0M3",
        "colab_type": "text"
      },
      "source": [
        "3. Loading validation data generator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4r5ukw7GT9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v_axial_data_generator = data_generator('MRNet-v1.0/', 'meniscus', 'axial', task = 1)\n",
        "v_sagittal_data_generator = data_generator('MRNet-v1.0/', 'meniscus', 'sagittal', task = 1)\n",
        "v_coronal_data_generator = data_generator('MRNet-v1.0/', 'meniscus', 'coronal', task = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0OI_pb3V_rt",
        "colab_type": "text"
      },
      "source": [
        "4. Preparing the training and validation data for the LR layer (predictions of the 3 models)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnlkaMheGT6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_all_predictions = predict_single_diagnosis(axial_model, sagittal_model, coronal_model, \n",
        "                                                t_axial_data_generator, t_sagittal_data_generator, t_coronal_data_generator)\n",
        "\n",
        "valid_all_predictions = predict_single_diagnosis(axial_model, sagittal_model, coronal_model, \n",
        "                                                v_axial_data_generator, v_sagittal_data_generator, v_coronal_data_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLODTfNlWHdx",
        "colab_type": "text"
      },
      "source": [
        "5. Fully connected (dense) layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THgGhFZ4GT3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dense_layer = Sequential([Dense(1, input_shape = (3, ), activation = 'sigmoid')])\n",
        "sgd = optimizers.SGD(lr=0.1)\n",
        "dense_layer.compile(optimizer=sgd, loss='binary_crossentropy', metrics = ['accuracy'])\n",
        "dense_layer.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cavAW2rhWNKA",
        "colab_type": "text"
      },
      "source": [
        "6. Training LR layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o3UJWLeWM3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_labels = load_labels_from_dir('MRNet-v1.0')\n",
        "train_labels = list(all_labels['train-meniscus']['label'])\n",
        "\n",
        "valid_labels = train_labels[1017:]\n",
        "train_labels = train_labels[:1017]\n",
        "\n",
        "validation = (np.array(valid_all_predictions), valid_labels)\n",
        "history = dense_layer.fit(np.array(train_all_predictions), train_labels, steps_per_epoch=1017, epochs=100, validation_data= validation, validation_steps= 113 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2jx-2ksGTyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_s2McqAWc42",
        "colab_type": "text"
      },
      "source": [
        "**Testing Phase:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_bqmUVpGTtY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading testing data generator\n",
        "axial_test_generator = data_generator('MRNet-v1.0/', 'meniscus', 'axial', task = 2)\n",
        "sagittal_test_generator = data_generator('MRNet-v1.0/', 'meniscus', 'sagittal', task = 2)\n",
        "coronal_test_generator = data_generator('MRNet-v1.0/', 'meniscus', 'coronal' , task = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OWBriJDWntu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test Input\n",
        "test_all_predictions = predict_single_diagnosis(axial_model, sagittal_model, coronal_model, \n",
        "                                                axial_test_generator, sagittal_test_generator, coronal_test_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8law49TwWosR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test Output\n",
        "all_labels = load_labels_from_dir('MRNet-v1.0')\n",
        "test_all_labels = list(all_labels['valid-meniscus']['label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o44SxvGMWojb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluation\n",
        "dense_layer.evaluate(np.array(test_all_predictions), test_all_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}